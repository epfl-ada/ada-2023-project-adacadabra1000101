{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0746bb-49a0-4944-b24c-e8473395ef9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#image analysis: first install dlib in your ada environment (1: conda activate ada , 2: install dlib)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m \n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m#face recognition library, first install it in your ada environment (1: conda activate ada, 2: install face_recognition)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mface_recognition\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "# import the appropriate libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import ast\n",
    "\n",
    "#image analysis: first install dlib in your ada environment (1: conda activate ada , 2: install dlib)\n",
    "import dlib \n",
    "#face recognition library, first install it in your ada environment (1: conda activate ada, 2: install face_recognition)\n",
    "import face_recognition\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c360c877-4dc5-4d80-b6ac-5ff5324a6318",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffcb12a-4a90-4acb-bc62-23da6775061c",
   "metadata": {},
   "source": [
    "Have you ever wondered why some actors keep getting cast in the same role? Why Dwayne Johnson always seems to plays the adventurous, headstrong and caring leader? Why Jason Staham is constantly cast as the gritty, hardboiled tough guy? And do these recurring casting choices lead to box office success? <br>\n",
    "This phenomenon is called typecasting, in which an actor becomes strongly identified with particular roles, or characters having the same traits or coming from the same social or ethnic groups. The CMU Movies Summary Corpus has already observed 501 recurring character tropes. In this study, we want to analyse the physical aspects of these tropes, by decoding the features *(gender, age, ethnicity and facial features)* of the actors observing them throughout time and movie genres, before correlating these findings to the movie's box office success. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916160b-022e-4203-9cbd-9cfca9a9ccb2",
   "metadata": {},
   "source": [
    "### Project Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9ab81-7f7e-4166-92b5-366a3fcf857b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Part 1: Exploring and pre-processing the data\n",
    "We identify the datasets of interest: *movies.metadata.tsv*, *characters.metadata.tsv* and *tvtropes.clusters.txt*.\n",
    "Let us first identify the variables of interest for our story. <br>\n",
    "- *Movie metadata: Wiki_movieID, Movie Name, Release Date, Box Office, Genres* <br>\n",
    "- *Character metadata: Wiki_movieID, Release Date, Character Name, Gender, Height, Ethinicity, Actor Name, Age at Movie Release* <br>\n",
    "\n",
    "**Step 1: Movie and Characters MetaData** <br>\n",
    "    - We plot our variables of interest to visualise distributions, range and/or aberrant outliers. <br>\n",
    "    - We analyse the percentage of missing data, giving us insight on how to complete them . <br>\n",
    "    - We merge movies.metadata.tsv with characters.metadata.tsv to associate the characters with their respective genres, movie box office revenue and decade of release. <br>\n",
    "    \n",
    "**Step 2: TV Tropes** <br>\n",
    "    - We pre-process our tvtropes.clusters.txt file and merge it with our merged character & movies metadata. We identify 501 character tropes with 72 unique tropes. <br>\n",
    "    - We complete key missing data such as Actor Age which we calculate using DOB and Release Date <br>\n",
    "    - Using WikiData, we convert the ethnicity labels to readable strings. <br>\n",
    "    - We filter it by grouping tropes and ethnicities together before visualizing it. <br>\n",
    "    - We do univariate and bivariate exploratory data analysis for our variables of interest. <br>\n",
    "    \n",
    "**Step 3: Extracting Actor Images** <br>\n",
    "    - We extract the 350 actor images from [The Movie Database](https://www.themoviedb.org/) to create the Actor_image.csv dataset. <br>\n",
    "    - We generated a personal API to extract the images URL and store them in a csv file with corresponding actor names.  We will use Dlib, a widely used pre-trained facial landmark detector to identify 68 key points on the face, storing them as pairs of coordinates. They will in turn used to derive additional features that we will link to the actors for our study. [Dlib annotations emphasize the importance of resolution and head pose accuracy in landmark placement. Illumination, quality, and color have a relatively minor impact](https://essay.utwente.nl/86867/1/Meijerink_BA_EEMCS.pdf). <br>\n",
    "    <p align = \"center\">\n",
    "        <img src = \"https://github.com/epfl-ada/ada-2023-project-adacadabra1000101/assets/145772112/a8839649-0450-4d0d-9b08-e1fdbca23b2e.png\" width = \"400\" height = \"400\"> <br>\n",
    "    </p>\n",
    "    - Despite having high-quality images and a well-trained model, we still encounter head pose challenges. In the upcoming steps, we will explore methods to rotate a 3D face to a pose comparable to a standard face. From these standardized images, we will extract facial landmarks to enhance the performance of the chosen model. <br>\n",
    "    \n",
    "### Part 2: Facial Image Analysis\n",
    "**Step 4: Extracting Facial Features** <br>\n",
    "    - We use the extracted coordinates to derive additional facial features of our actor images.<br>\n",
    "    - Our continuous features are calculated from the landmarks. We will address proportional considerations when comparing actor images, as length between landmarks does not provide information without a reference length. <br>\n",
    "    - Proportionality also has the side benefit of normalizing our values. <br>\n",
    "\n",
    "**Step 5: Analysing and Selecting Facial Features** <br>\n",
    "    - We analyse and select the facial features that are most pertinent to our study, by correlating them with our tropes-character-movies data. <br>\n",
    "    - We re-extract more features once the head-pose accuracy issue has been fixed. <br>\n",
    "\n",
    "### Part 3: Classifying our data\n",
    "**Step 6: Putting all the features together** <br>\n",
    "    - We put all the features, obtained from tropes-character-movies and the facial image analysis. <br>\n",
    "    - We filter the features, keeping only the most important. <br>\n",
    "    - We select a model and tune its parameters <br>\n",
    "\n",
    "### Part 4: Data Analysis\n",
    "**Step 7: Analysis** <br>\n",
    "    - We analyse our data and find answers to our research questions. <br>\n",
    "\n",
    "### Part 5: Story-Telling\n",
    "**Step 8: Web Design** <br>\n",
    "    - We use our findings to create our story on the webpage. <br>\n",
    "\n",
    "### Part 6: When the fun *finally* begins\n",
    "**Step 9: Adding our own images** <br>\n",
    "    - We add our own images and use what we found earlier to determine what character trope would suit each of us best. <br>\n",
    "\n",
    "***BONUS step: Adding an interactive feature*** <br>\n",
    "    - We add a feature where a user can upload his own image and/or fill a form. We would then analyse his image and/or form to show the character trope that suits the user best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099b7c8-b04b-4478-bae8-333418b6b44b",
   "metadata": {},
   "source": [
    "#### Ethical Risks of our study\n",
    "+ CMU Movie Summaries Corpus regroups a mix of nationalities and ethnicities for ActorEthnicity *(for example: Japanese Brasilians)*. We decided to cluster similar ActorEthnicity values together. This runs the risk of misrepresentation as we will potentially different ethnic groups together.\n",
    "+ We use and analyze actor images from [The Movie Database](https://www.themoviedb.org/) (TMDB). As such, we are subject to the conditions detailed in TMDB's [Terms of Use](https://www.themoviedb.org/terms-of-use), notably in terms of the actors' image consent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10999b92-cc04-4ccc-a6cb-22884f44201c",
   "metadata": {},
   "source": [
    "## Step 1: Movie and Characters MetaData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a832b61-ae2b-4e30-9159-061e6760ebae",
   "metadata": {},
   "source": [
    "### a) Loading Data and Identifying variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c55e79-e34b-44aa-9f21-06bd4a065f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Loading our data\n",
    "characters_df = pd.read_csv('data/character.metadata.tsv', delimiter=\"\\t\", \n",
    "                            names=['Wiki_movieID', 'Freebase_movieID', 'ReleaseDate', 'CharacterName', 'ActorDOB', 'ActorGender', 'ActorHeight', 'ActorEthnicity', 'ActorName', 'ActorAge', 'Freebase_charactermap', 'Freebase_characterID', 'Freebase_actorID'])\n",
    "movies_df = pd.read_csv('data/movie.metadata.tsv', delimiter=\"\\t\", \n",
    "                        names=['Wiki_movieID', 'Freebase_movieID', 'MovieName', 'ReleaseDate', 'BoxOffice', 'Runtime', 'Languages', 'Countries', 'Genres'])\n",
    "\n",
    "#We look at the length and shape of our initial dataframes.\n",
    "print(\"Size of 'Characters' DataFrame: %d\" % len(characters_df))\n",
    "print(\"Size of 'Movies' DataFrame: %d\" % len(movies_df))\n",
    "\n",
    "print(\"Shape of 'Characters' DataFrame: %d\" % characters_df.shape[1])\n",
    "print(\"Shape of 'Movies' DataFrame: %d\" % movies_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62de7def-ae2f-44c9-8d0d-b2a0fefb2e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display column names and first line of characters dataframe\n",
    "characters_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8319d6-b943-4aa2-a9a1-8823a823013f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#display column names and first line of movies dataframe\n",
    "movies_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2819a45-3d3b-4887-87ad-d9606b7735ab",
   "metadata": {},
   "source": [
    "We identify the variables of interest for our project.\n",
    "+ Movie metadata: *Wiki_movieID, MovieName, ReleaseDate, Genres, BoxOffice* <br>\n",
    "+ Character metadata: *Wiki_movieID, ReleaseDate, CharacterName, ActorGender, ActorHeight, ActorEthinicity, ActorName, ActorAge* <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388afc68-cb6c-4d26-927e-e08d9d0bf548",
   "metadata": {},
   "source": [
    "### b) Cleaning and Sorting our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fe0bd-b668-45e3-b44c-d1a94cfe62ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Functions used for cleaning and sorting of data\n",
    "\n",
    "def percentage_missingdata(dataframe, column_name):\n",
    "# get the percentage of missing data from a column of a dataframe\n",
    "# Args: dataframe: dataframe of the column, column_name\n",
    "# Returns: percentage_missing\n",
    "    notmissing = dataframe[column_name].count()\n",
    "    totaldata = len(dataframe[column_name])\n",
    "    percentage_missing = (1 - (notmissing/totaldata)) * 100\n",
    "    \n",
    "    return percentage_missing\n",
    "\n",
    "def is_valid_date(date_string, format_string):\n",
    "# is the date given valid in the given format\n",
    "# Args: date_string : date to test, format_string: expected format\n",
    "# Returns: boolean\n",
    "    try:\n",
    "        datetime.strptime(date_string, format_string)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cca007-595f-4af5-86e7-9d38919e2842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#change the {} (empty dict) into NaNs\n",
    "movies_df.replace({'{}': pd.NA}, inplace=True)\n",
    "characters_df.replace({'{}': pd.NA}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e27a87-b55f-4d58-9e3c-d68109ae3ac3",
   "metadata": {},
   "source": [
    "#### b.i) Sorting and Visualising our Movie Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec7322-32c2-4dc3-b11c-9b80bc62eb74",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Decades of Release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ca5798-2379-428e-b294-d3e58e398629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We start by classifying our data per decades of release dates.\n",
    "#Keeping only the year of release of the movies to classify them by decades\n",
    "format1 = \"%Y-%m-%d\"\n",
    "format2 = \"%Y-%m\"\n",
    "\n",
    "for y in range(len(movies_df)):\n",
    "    if isinstance(movies_df['ReleaseDate'][y], str):\n",
    "        if is_valid_date(movies_df['ReleaseDate'][y],format1):\n",
    "            date_obj = datetime.strptime(movies_df['ReleaseDate'][y], format1)\n",
    "            movies_df.loc[y,'ReleaseDate'] = date_obj.year\n",
    "            \n",
    "    if isinstance(movies_df['ReleaseDate'][y], str):\n",
    "        if is_valid_date(movies_df['ReleaseDate'][y],format2):\n",
    "            date_obj = datetime.strptime(movies_df['ReleaseDate'][y], format2)\n",
    "            movies_df.loc[y,'ReleaseDate'] = date_obj.year\n",
    "            \n",
    "movies_df['ReleaseDate'] = movies_df['ReleaseDate'].astype(float)\n",
    "movies_df.sort_values(by='ReleaseDate', ascending=True, inplace=True)\n",
    "\n",
    "#Visualization\n",
    "display(movies_df[['MovieName', 'ReleaseDate', 'Genres', 'BoxOffice']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03120ba6-52fd-4d55-8e3b-4bc2d1faa0c9",
   "metadata": {
    "tags": []
   },
   "source": [
    ">We notice an error in the movies dataset. The movie 'Hunting Season' is said to have a release date in 1010. This is impossible as the first movie was made in 1888, named 'Roundhay Garden Scene'. <br>\n",
    ">A quick google search reveals that the movie's actual release year was 2010. Let us fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f97d6f-56a5-412f-a53d-7af8b2561670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "huntingseason_error = movies_df.loc[movies_df['MovieName'] == 'Hunting Season'].index\n",
    "movies_df.loc[huntingseason_error,'ReleaseDate'] = 2010.0\n",
    "\n",
    "#display after correction\n",
    "display(movies_df[['MovieName', 'ReleaseDate', 'Genres', 'BoxOffice']].head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c1331-0d18-4051-b329-4166f83033d7",
   "metadata": {},
   "source": [
    "> We notice two movies released in 1888 and 1889. To not have just two values in the 1880s decade, we decide to add these two movies to the 1890s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b376c22b-ef0b-47da-91c3-97721bd157c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This function returns the decade of the movie's release date.\n",
    "def get_decade(year):\n",
    "    return (year // 10) * 10\n",
    "\n",
    "#Let us start by adding the decades to movies_df\n",
    "if 'Decade' not in movies_df.columns:\n",
    "    movies_df.insert(5, 'Decade', None)\n",
    "\n",
    "movies_df['Decade'] = movies_df['ReleaseDate'].apply(lambda x: get_decade(x))\n",
    "\n",
    "#As said earlier, we add the two movies released in 1888 and 1889 to the 1890s decades. \n",
    "decade_change1 = movies_df.loc[movies_df['ReleaseDate'] == 1888].index\n",
    "movies_df.loc[decade_change1,'Decade'] = 1890.0\n",
    "\n",
    "decade_change2 = movies_df.loc[movies_df['ReleaseDate'] == 1889].index\n",
    "movies_df.loc[decade_change2,'Decade'] = 1890.0\n",
    "\n",
    "# diplay these firest years and the decade they were assigned to\n",
    "movies_df.sort_values(by='ReleaseDate' , ascending=True, inplace=True)\n",
    "display(movies_df[['MovieName', 'Genres', 'Decade', 'ReleaseDate']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c389f66a-b947-4551-9768-71ee39665a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple plot of number of movies released per decade\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.countplot(x='Decade', data=movies_df, palette='viridis')\n",
    "plt.title('Number of Movies Released per Decade')\n",
    "plt.xlabel('Decade')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b6819-8866-4528-bd5f-e83bfd511e18",
   "metadata": {},
   "source": [
    "> We observe a gradual increase in number of movies until the 1980s *(with a drop in the 1940s due to WWII)* with a sudden burst in movie quantity in the 1990s and 2000s. <br>\n",
    "> There is a small sample size for the 2010s because the data collected until 2016 only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f7f95a-1340-4a53-b8f5-0adb10b551e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Movie Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd59de-e52b-4757-a2e4-8efcc75ec1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Keeping only the name of the genre in our dataframe, instead of a dict with the freebase ID of the genre\n",
    "\n",
    "genre_names_list = []\n",
    "\n",
    "for gen in range(len(movies_df)):\n",
    "    if pd.notna(movies_df['Genres'][gen]) and isinstance(movies_df['Genres'][gen], str):\n",
    "        genre_dict = json.loads(movies_df['Genres'][gen])\n",
    "        genre_names = list(genre_dict.values())\n",
    "        genre_names_list.append(genre_names)\n",
    "    else:\n",
    "        genre_names_list.append(pd.NA)\n",
    "\n",
    "movies_df.sort_index(ascending=True, inplace=True)\n",
    "movies_df['Genres'] = genre_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e9763-7374-40d4-9478-6e06644a42f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Flattening all the genres list into one single list to be able to count their occurencies\n",
    "copy = movies_df.copy()\n",
    "movies_df_exploded = copy.explode('Genres')\n",
    "movies_df_exploded = movies_df_exploded[movies_df_exploded['Genres'] != '{}']\n",
    "flattened_list = movies_df_exploded['Genres'].tolist()\n",
    "\n",
    "genres_counts = Counter(flattened_list)\n",
    "counts_df = pd.DataFrame.from_dict(genres_counts, orient='index', columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb69f3-6023-49e5-b042-eb5069acb1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting movies by genres\n",
    "\n",
    "#We notice that there's 2294 counts of films with missing genres, characterised by an NaN value. \n",
    "#As such we determine our threshold to be over 2300 for the genre occurences.\n",
    "counts_df = counts_df[counts_df['Count'] >= 2300]\n",
    "\n",
    "counts_df.sort_values(by='Count', ascending=True, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x=counts_df.index.tolist(), y=counts_df['Count'])\n",
    "sns.regplot(x=np.arange(len(counts_df)), y=counts_df['Count'], order=7, scatter=False, color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(bottom=0, top=35000)\n",
    "plt.xlabel('Most Prevalent Genres')\n",
    "plt.ylabel('Number of Movies')\n",
    "plt.title('Number of Movies per Genre')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd390e1d-9653-447b-92c5-8585e795be30",
   "metadata": {},
   "source": [
    "> We observe the 26 most prevalent movie genres in our database *(with more than 2400 movies per genre)* <br>\n",
    "> A majority of the movies are dramas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc37464-eb41-4041-a0b3-286192b9c9f1",
   "metadata": {},
   "source": [
    "#### b.ii) Checking the percentage of missing data for each variable of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3b80d-e253-4939-8f32-03f1f508184f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Missing data in movies_df\n",
    "movie_variables = ['Wiki_movieID', 'MovieName', 'ReleaseDate','Genres', 'BoxOffice']\n",
    "percentage_missing_movies = []\n",
    "\n",
    "percentage_missing_movies = [percentage_missingdata(movies_df, var) for var in movie_variables]\n",
    "\n",
    "missing_data_movies_df = pd.DataFrame({'Variables of Interest': movie_variables,\n",
    "                                           'Percentage of Missing Data': percentage_missing_movies})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d67ad-2331-4596-888e-7643768b80dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting the percentage of missing data for the variables of movies_df\n",
    "plt.figure(figsize=(6, 3))\n",
    "bars = plt.bar(missing_data_movies_df['Variables of Interest'], missing_data_movies_df['Percentage of Missing Data'])\n",
    "plt.ylim(0, 100)\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 1), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Variables of Interest')\n",
    "plt.ylabel('Missing Data (in %)')\n",
    "plt.title('Percentage of Missing Data per Variable in the Movies DataFrame')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7104d55e-741c-46b7-b1f6-f889b435edfe",
   "metadata": {},
   "source": [
    ">We observe 0% of missing data for Wiki_movieID and Movie Name. We can associate each movie to its respective Wikipedia Page using WikiData without any errors.<br>\n",
    ">We have 8.4% of missing data for Release Date variable and 2.8% for Genres variable. These values are both very low and under 10%. Generally, when we have more than 10% of missing data, our data is likely to be biased. As such this is not the case for these two variables.<br>\n",
    ">We see however 89.7% of missing data for the BoxOffice variable, an astonishing amount. This will mean that our BoxOffice is very likely to be biased towards the movies that have a BoxOffice value.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc9df35-efce-4ee8-a3b9-ca389cbea92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Missing data in characters_df\n",
    "character_variables = ['Wiki_movieID', 'ReleaseDate', 'CharacterName','ActorGender', 'ActorHeight', \n",
    "                                                    'ActorEthnicity', 'ActorName', 'ActorAge','ActorDOB']\n",
    "percentage_missing_characters = []\n",
    "\n",
    "percentage_missing_characters = [percentage_missingdata(characters_df, var) for var in character_variables]\n",
    "\n",
    "missing_data_characters_df = pd.DataFrame({'Variables of Interest': character_variables,\n",
    "                                           'Percentage of Missing Data': percentage_missing_characters})                                                                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5fd1e-cc3a-46d2-90e8-bbc4a1c64c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting the percentage of missing data for the variables of characters_df\n",
    "plt.figure(figsize=(6, 4))\n",
    "bars = plt.bar(missing_data_characters_df['Variables of Interest'], missing_data_characters_df['Percentage of Missing Data'])\n",
    "plt.ylim(0, 100)\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 1), ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Variables of Interest')\n",
    "plt.ylabel('Missing Data (in %)')\n",
    "plt.title('Percentage of Missing Data per Variable in the Characters DataFrame')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a99ea-c191-44b9-99b9-6f3da6c6e007",
   "metadata": {},
   "source": [
    ">We observe a high percentage of missing data for our respective variables of interest, the notable ones being *CharacterName*, *ActorHeight*, *ActorEthnicity* and *ActorDOB*, *ActorAge*.<br>\n",
    "> For character name, this missing data is to be expected as many characters in movies do not have names, being background characters. Their character roles are much more interesting for our analysis. <br>\n",
    "> Similarly, the missing data in actor age and actor date of birth (DOB) is not an issue as we can use DOB and Release Date to calculate the actor's age. The inverse is true to find the DOB. We can clean these missing values. <br>\n",
    "> Our biggest concern is with the large quantity of missing data in both actor height and ethnicity as they are both key features to our project idea. We can use WikiData to complete our data. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9cdee-cbcf-44a8-a834-277b85838f53",
   "metadata": {},
   "source": [
    "### c) Merging Movie and Character DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c030a-edd2-4700-ad04-0cd18828864b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_movies_df = movies_df.merge(characters_df, on=['Wiki_movieID'], how = 'left', suffixes=(\"\", \"_y\")).drop(['Freebase_movieID_y', 'ReleaseDate_y'], axis=1)\n",
    "\n",
    "#Visualization\n",
    "display(characters_movies_df[['CharacterName', 'ActorName', 'ActorAge', 'ActorDOB', 'ActorEthnicity',\n",
    "                                  'ActorGender','ActorHeight', 'MovieName', 'Genres', 'Decade', 'ReleaseDate', 'BoxOffice']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fca24a-2a59-4fd1-8dd7-14afa6fb1491",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Counting the number of characters per movie genre\n",
    "characters_movies_copy = characters_movies_df.copy()\n",
    "c_m_exploded = characters_movies_copy.explode('Genres')\n",
    "c_m_exploded = c_m_exploded[c_m_exploded['Genres'] != '{}']\n",
    "flat_list = c_m_exploded['Genres'].tolist()\n",
    "\n",
    "charac_counts = Counter(flat_list)\n",
    "charac_counts_df = pd.DataFrame.from_dict(charac_counts, orient='index', columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5908d4a3-d046-46b1-8a57-2e1b3a5e999a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "charac_counts_df = charac_counts_df[charac_counts_df['Count'] >= 15000]\n",
    "\n",
    "charac_counts_df.sort_values(by='Count', ascending=True, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.barplot(x=charac_counts_df.index.tolist(), y=charac_counts_df['Count'])\n",
    "sns.regplot(x=np.arange(len(charac_counts_df)), y=charac_counts_df['Count'], order=7, scatter=False, color='red')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(bottom=0, top=200000)\n",
    "plt.xlabel('Most Prevalent Genres')\n",
    "plt.ylabel('Number of Characters')\n",
    "plt.title('Number of Characters per Genre')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4824cf-19cc-464f-ba71-d15744f46b20",
   "metadata": {},
   "source": [
    ">We plot the number of characters per genre. The distribution matches the earlier plotted distribution of number of movies per genre with a majority of characters being in dramas or comedies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ded4b2-558d-4e46-8f3e-eefb9a68828c",
   "metadata": {},
   "source": [
    "## Step 2: TV Tropes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76979e4-18a1-47d4-96b8-c8d5afa3d049",
   "metadata": {},
   "source": [
    "### a) Visualising our TV Tropes Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18e902-0cf7-4c8b-be83-13d08337d237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_tropes_original = pd.read_csv('data/tvtropes.clusters.txt', delimiter=\"\\t\", names=['trope', 'character'])\n",
    "json_obj = df_tropes_original['character'].apply(json.loads)\n",
    "df_tropes_norm = pd.json_normalize(json_obj[0])\n",
    "\n",
    "for i in range(1, len(json_obj)):\n",
    "    df_norm = pd.json_normalize(json_obj[i])\n",
    "    df_tropes_norm = pd.concat([df_tropes_norm, df_norm], ignore_index=True)\n",
    "\n",
    "tropes_df = pd.concat([df_tropes_original.drop('character', axis=1), df_tropes_norm], axis=1)\n",
    "\n",
    "tropes_df = tropes_df.rename(columns={'id': 'Freebase_charactermap', 'char':'CharacterName', 'actor':'ActorName', 'movie':'MovieName'})\n",
    "\n",
    "#Visualizing tropes_df data\n",
    "display(tropes_df.head())\n",
    "print(\"Size of 'Tropes' DataFrame: %d\" % len(tropes_df))\n",
    "print(\"Shape of 'Tropes' DataFrame: %d\" % tropes_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f7b6d-a4a9-4b0e-88dc-b16cedb63640",
   "metadata": {
    "tags": []
   },
   "source": [
    ">We visualise our tvtropes.clusters as a dataframe and we observe 501 character tropes with 72 unique types. We will now merge it with our characters_movies_df to associate the characters to their respective tropes. <br> \n",
    ">We will then check for missing data in this new merged dataframe. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e879d910-bb3e-40af-9fdc-ea5061cf05e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### b) Merging Character & Movies Dataframe on TV Tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978235bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# population de tropes_df with the df containing the movies and characters\n",
    "tropes_movie_character_df= pd.merge(tropes_df, characters_movies_df, on=['CharacterName', 'ActorName', 'MovieName', 'Freebase_charactermap'], how='left').drop(['Runtime', 'Languages', 'Countries','Freebase_characterID'], axis=1)\n",
    "new_order=['Freebase_charactermap', 'trope', 'CharacterName', 'ActorName', 'ActorAge','ActorDOB', 'ActorEthnicity', 'ActorGender', 'ActorHeight', 'Freebase_actorID', 'MovieName', 'Genres','Decade', 'ReleaseDate', 'BoxOffice', 'Freebase_movieID','Wiki_movieID' ]\n",
    "tropes_movie_character_df=tropes_movie_character_df[new_order]\n",
    "tropes_movie_character_df=tropes_movie_character_df.rename(columns={'trope': 'Trope'})\n",
    "tropes_movie_character_df=tropes_movie_character_df.sort_values('Trope')\n",
    "\n",
    "#Visualiszing our merged dataframe, tropes_movie_character_df:\n",
    "display(tropes_movie_character_df[['Trope', 'CharacterName', 'ActorName', 'ActorAge', 'ActorDOB', 'ActorEthnicity',\n",
    "                                  'ActorGender','ActorHeight', 'MovieName', 'Genres', 'Decade', 'ReleaseDate', 'BoxOffice']]\n",
    "                                  .head(3))\n",
    "print(\"Size of 'Tropes-Movie-Character' DataFrame: %d\" % len(tropes_movie_character_df))\n",
    "print(\"Shape of 'Tropes-Movie-Character' DataFrame: %d\" % tropes_movie_character_df.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a79a358-4e80-4121-a309-a17799c3fa31",
   "metadata": {},
   "source": [
    ">The size of our dataframe matches the size of our Tropes DataFrame indicating a correct merge. We have associated the 501 character tropes to their respective characters, movies and features *(Actor Name, Movie Genre, Actor Ethnicity...)*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413f6c-a863-426e-adb4-7e983ed8e637",
   "metadata": {
    "tags": []
   },
   "source": [
    "### c) Visualising the missing data in TV Tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a8b51-770a-4ed5-b23d-6734091dd465",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Missing data for tropes\n",
    "tropes_variables = ['Wiki_movieID', 'MovieName', 'ReleaseDate','Genres', 'BoxOffice', 'CharacterName','ActorGender', 'ActorHeight', \n",
    "                                                    'ActorEthnicity', 'ActorName', 'ActorAge','ActorDOB']\n",
    "percentage_missing_tropes_data = []\n",
    "\n",
    "percentage_missing_tropes_data = [percentage_missingdata(tropes_movie_character_df, var) for var in tropes_variables]\n",
    "    \n",
    "missing_data_tropes_df = pd.DataFrame({'Variables of Interest': tropes_variables,\n",
    "                                           'Percentage of Missing Data': percentage_missing_tropes_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27abc270-4e22-4de7-aa72-64e016af8c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Plotting the percentage of missing data for the variables of missing_data_tropes_df\n",
    "plt.figure(figsize=(5, 4))\n",
    "bars = plt.bar(missing_data_tropes_df['Variables of Interest'], missing_data_tropes_df['Percentage of Missing Data'])\n",
    "plt.ylim(0, 100)\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 1), ha='center', va='bottom')\n",
    "\n",
    "plt.xlabel('Variables of Interest')\n",
    "plt.ylabel('Percentage of Missing Data (in %)')\n",
    "plt.title('Percentage of Missing Data per Variable in the Movies DataFrame')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb09fb15-df1e-42e6-b0c5-2c3f4017f542",
   "metadata": {},
   "source": [
    ">We notice a dramatic decrease in missing data compared to our movies_df and characters_df dataframes, with relatively small amounts for all the variables of interests except *ActorEthnicity*. <br>\n",
    ">We will now clean our data, starting with the 3.6% of missing data in Actor Age that we can easily fix using ActorDOB. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30ccda-7022-4cc0-b491-ba3af0584f42",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### c.i) Filling the missing data in Actor Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849382bf-3b83-42be-853e-d62be08758fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Finding the entries missing both ActorAge and ActorDOB\n",
    "missing_age=tropes_movie_character_df[tropes_movie_character_df['ActorAge'].isna() & tropes_movie_character_df['ActorDOB'].isna()]\n",
    "\n",
    "#Display the entries missing both ActorAge and ActorDOB\n",
    "display(missing_age[['Trope', 'CharacterName', 'ActorName', 'ActorAge', 'ActorDOB', 'ReleaseDate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9094d-f59f-4f66-a07e-a6f542337934",
   "metadata": {},
   "source": [
    "> As before, we want to fill the 3.6% of missing data in Actor Age by calculating it with the date of birth of the actor and the year of release. \n",
    "> As noted in the table above, only two actors do not have either Actor Age or Date of Birth, as such we might have to manually fill in the data for these two actors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2142a2-1cf6-48b6-b17c-d596ea754f13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Converting DOB to Years\n",
    "for y in range(len(tropes_movie_character_df)):\n",
    "    if isinstance(tropes_movie_character_df['ActorDOB'][y], str):\n",
    "        if is_valid_date(tropes_movie_character_df['ActorDOB'][y],format1):\n",
    "            date_obj = datetime.strptime(tropes_movie_character_df['ActorDOB'][y], format1)\n",
    "            tropes_movie_character_df.loc[y,'ActorDOB'] = date_obj.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79333fb3-a8b1-4c12-88b5-f8a5b2efa226",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculating Actor Ages and filling the missing data\n",
    "tropes_movie_character_df['ActorDOB'] = tropes_movie_character_df['ActorDOB'].astype(float)\n",
    "\n",
    "tropes_movie_character_df['ActorAge'] = tropes_movie_character_df['ReleaseDate'] - tropes_movie_character_df['ActorDOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524857ad-24c8-40eb-9c85-385a43f9d6ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Checking missing data in ActorAge again\n",
    "age_variables = ['ActorAge','ActorDOB']\n",
    "percentage_missing_tropes_age = []\n",
    "\n",
    "percentage_missing_tropes_age = [percentage_missingdata(tropes_movie_character_df, var) for var in age_variables]\n",
    "  \n",
    "missing_data_tropes_age = pd.DataFrame({'Variables of Interest': age_variables,\n",
    "                                           'Percentage of Missing Data': percentage_missing_tropes_age})\n",
    "\n",
    "print(missing_data_tropes_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2138cfbc-761f-4600-8c27-e04854d7347a",
   "metadata": {},
   "source": [
    ">As seen in the table above, we have successfully completed the missing data in Actor Age, with the percentage decreasing from 3.6% to 0.399% *(the percentage of missing data for ActorDOB)*. <br>\n",
    ">With a quick calculation, we observe that the remaining 0.399% of missing data in Actor Age and Actor Date of Birth corresponds to the two actors we identified earlier who do not have values for both ActorAge and ActorDOB. Let us manually add these values to our data frame. <br>\n",
    "<br>\n",
    "> Our missing actors and characters are: <br> - *Prince Otwani played by Trevor Thomas in the movie 'Sheena'*  <br> - *Prince Yu played by Junjie Qin in the movie 'Curse of the Golden Flower'* <br>\n",
    "> Upon printing the rows with missing data for both ActorAge and ActorDOB above, we identified the indexes for both missing values: index 233 for Trevor Thomas and 227 for Junjie Qin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6395c1b0-02eb-4d19-9624-7a7fae8581e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tropes_movie_character_df.loc[227,'ActorDOB'] = 1991.0\n",
    "tropes_movie_character_df.loc[227, 'ActorAge'] = tropes_movie_character_df['ReleaseDate'][227] - tropes_movie_character_df['ActorDOB'][227] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4892d88a-35c9-4eb7-bee5-257312c06895",
   "metadata": {},
   "source": [
    "> Despite our best efforts, we could not find any information on Trevor Thomas on his date of birth or age. As such, we decide to leave him as a missing value for our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7e32cb-4ed0-4273-a45c-0f85925a2871",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#We print the percentage of missing data for tropes_movie_character_df one last time.\n",
    "percentage_missing_tropes_age_new = []\n",
    "\n",
    "percentage_missing_tropes_age_new = [percentage_missingdata(tropes_movie_character_df, var) for var in age_variables]\n",
    "    \n",
    "missing_data_tropes_age_new = pd.DataFrame({'Variables of Interest': age_variables,\n",
    "                                           'Percentage of Missing Data': percentage_missing_tropes_age_new})\n",
    "\n",
    "print(missing_data_tropes_age_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6ac2ec-f543-43c0-a807-b5c761ad8655",
   "metadata": {},
   "source": [
    "> We now have less than 0.2% of missing data for both ActorDOB and ActorAge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0bd05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_ethn=tropes_movie_character_df[tropes_movie_character_df['ActorEthnicity'].isna()]\n",
    "\n",
    "print('The number of actors with missing ActorEthnicity values: %d' %len(missing_ethn['ActorName']))\n",
    "print('This matches the 33.5% of missing data calculated above.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9553a36",
   "metadata": {},
   "source": [
    "#### d) Transforming the ActorEthnicity label in a string using [WikiData](https://query.wikidata.org/sparql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aa481d-d55e-4c33-b3dd-bf5b271cefd2",
   "metadata": {},
   "source": [
    "> We observe that the ActorEthnicity is charactertised by a label, for example */m/09v5bdn*. Let us use WikiData to retrieve these labels and display them in a readable fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885ea9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ethnicity(freebase_id):\n",
    "    # get the label of the freebase ID from Wikidata\n",
    "    # Args: freebase_id: the freebase ID to be decoded\n",
    "    # Returns: label, the corresponding label of the Wikidata ID (and a specific text for when)\n",
    "    \n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    query = \"\"\"\n",
    "    SELECT ?item ?itemLabel WHERE {\n",
    "      ?item wdt:P646 '\"\"\" + freebase_id + \"\"\"'.\n",
    "      SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
    "    }\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(endpoint_url)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        if results[\"results\"][\"bindings\"]:\n",
    "            label = results[\"results\"][\"bindings\"][0][\"itemLabel\"][\"value\"]\n",
    "            return label\n",
    "        else:\n",
    "            return \"Label not found for the specified Freebase ID\"\n",
    "    except Exception as e:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af555299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# groups by ethnicity, to get all the different ethnicities in one table\n",
    "temp_df = tropes_movie_character_df['ActorEthnicity'].groupby(tropes_movie_character_df['ActorEthnicity']).agg(['count'])\n",
    "temp_df = temp_df.reset_index()\n",
    "temp_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3b4882-b2ad-459d-a1c2-0022d5097879",
   "metadata": {},
   "source": [
    "> As seen above, we have all the ethnicities in one table labelled in a key. We will use WikiData match every freebase ethnicity ID to its corresponding word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0082a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Match every freebase ethnicity ID to the ethnicity, if it found in Wikidata\n",
    "temp_temp_df = temp_df.copy()\n",
    "et = []\n",
    "for i in range(len(temp_df['ActorEthnicity'])):\n",
    "    df_temp_ethnicity = temp_df.iloc[i:i+1]\n",
    "    for ethnicity in df_temp_ethnicity['ActorEthnicity'] :\n",
    "        eth_tra = get_ethnicity(ethnicity)\n",
    "        j = 0\n",
    "        while ((type(eth_tra) == float) & (j<100)):\n",
    "            #print(type(get_ethnicity(ethnicity)))\n",
    "            eth_tra = get_ethnicity(ethnicity)\n",
    "            j += 1\n",
    "        et.append(eth_tra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbe6087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "temp_temp_df['StrActorEthnicity'] = et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6149c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#convert to string every ethnicity taken from Wikidata\n",
    "tmp = []\n",
    "for i in range (len(temp_temp_df['StrActorEthnicity'])):\n",
    "    if not (pd.isna(temp_temp_df['StrActorEthnicity'][i])):\n",
    "        tmp.append(str(temp_temp_df['StrActorEthnicity'][i]))\n",
    "    else:\n",
    "        tmp.append(temp_temp_df['StrActorEthnicity'][i])\n",
    "temp_temp_df['StrActorEthnicity'] = tmp\n",
    "ethnicity_decoding = temp_temp_df\n",
    "\n",
    "#len(ethnicity_decoding['StrActorEthnicity'])\n",
    "ethnicity_decoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8692287-304d-4840-80eb-a6c72befc697",
   "metadata": {},
   "source": [
    "> We associated the Actor Ethnicity labels to their respective strings. We observe another issue though. <br>\n",
    "> We have a very large number of ethnicities with very precise descriptions, for example *Asian American, Korean American...* We decide to simplify and group our ethnicities together. <br>\n",
    "> We do this by deleting the word *\"people\"* and \"*person*\" after space, allowing for example *Irish* and *Irish people* to merge into the same category. We also assume the first ethnicity to be more representative then \"*american\"*. For example, \"*Korean American*\" will be labelled in our dataset as *Korean*. <br>\n",
    "> We also transform all the uppercases into lowercases. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a374c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simplifying the ethnicity_decoding dataframe. \n",
    "simple_ethnicity_decoding = ethnicity_decoding.copy()\n",
    "simple_ethnicity_decoding['StrActorEthnicity'] = simple_ethnicity_decoding['StrActorEthnicity'].str.replace(' Americans', '')\n",
    "simple_ethnicity_decoding['StrActorEthnicity'] = simple_ethnicity_decoding['StrActorEthnicity'].str.replace(' American', '')\n",
    "simple_ethnicity_decoding['StrActorEthnicity'] = simple_ethnicity_decoding['StrActorEthnicity'].str.replace(' people', '')\n",
    "simple_ethnicity_decoding['StrActorEthnicity'] = simple_ethnicity_decoding['StrActorEthnicity'].str.replace(' person', '')\n",
    "simple_ethnicity_decoding['StrActorEthnicity'] = simple_ethnicity_decoding['StrActorEthnicity'].str.lower()\n",
    "len(simple_ethnicity_decoding['StrActorEthnicity'].unique())\n",
    "simple_ethnicity_decoding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370f916-bebf-4513-a479-8c98dcf48ad1",
   "metadata": {
    "tags": []
   },
   "source": [
    ">We observe the results of ethnicity simplication above, with *Asian American* becoming *Asian* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fa6e9-5d09-4afb-b0d4-27752cb2ed5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tropes_characters_ethnicity_df = tropes_movie_character_df.merge(simple_ethnicity_decoding, on='ActorEthnicity', how='left').drop(['count'], axis = 1)\n",
    "tropes_characters_ethnicity_df.sort_values(by='CharacterName', ascending=True, inplace=True)\n",
    "tropes_characters_ethnicity_df = tropes_characters_ethnicity_df.rename(columns={'ActorEthnicity': 'ActorEthnicity Label'})\n",
    "\n",
    "#Visualizing our data\n",
    "display(tropes_characters_ethnicity_df[['Trope', 'CharacterName', 'ActorName', 'ActorEthnicity Label', 'StrActorEthnicity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21bd5c-871f-415d-86b6-172c00527f16",
   "metadata": {},
   "source": [
    "> As seen above, we successfully retrieved the actor ethnicities for the 67.5% of actors with ActorEthnicity labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f47693-34ca-4bcb-abc9-3d4dc8c57415",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#finding the number of labels for which the function was unable to retrieve a label, the ethnicity is saved as 'Label not found for the specified Freebase ID'\n",
    "missing_label_df = tropes_characters_ethnicity_df[tropes_characters_ethnicity_df['StrActorEthnicity'].str.contains('Label', case=False, na=False)]\n",
    "\n",
    "#we replace the text 'Label not found for the specified Freebase ID' by np.Na as it is unusable data\n",
    "tropes_characters_ethnicity_df['StrActorEthnicity'].replace({'label not found for the specified freebase id': pd.NA}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06201bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting the number of characters per ethnicity\n",
    "tropes_characters_ethnicity_copy = tropes_characters_ethnicity_df.copy().dropna()\n",
    "flat_list_ethn = tropes_characters_ethnicity_copy['StrActorEthnicity'].tolist()\n",
    "\n",
    "tropes_counts = Counter(flat_list_ethn)\n",
    "tropes_counts_df = pd.DataFrame.from_dict(tropes_counts, orient='index', columns=['Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17615ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the number of characters per ethnicity using the counts from the previous cell\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "tropes_counts_df.sort_values(by='Count', ascending=True, inplace=True)\n",
    "\n",
    "sns.barplot(x=tropes_counts_df.index.tolist(), y=tropes_counts_df['Count'])\n",
    "sns.regplot(x=np.arange(len(tropes_counts_df)), y=tropes_counts_df['Count'], order=7, scatter=False, color='red', ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(bottom=0, top=42)\n",
    "plt.xlabel('Ethnicities')\n",
    "plt.ylabel('Number of Characters')\n",
    "plt.title('Number of Characters per Ethnicity')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2900284-db9b-498c-8e39-e9d5905e9b20",
   "metadata": {},
   "source": [
    "### d) Plotting the data in our merged tropes_characters df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e2f599-e1e9-45be-9033-1237592f2b02",
   "metadata": {},
   "source": [
    "#### d.i) Univariate Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1807efd9-ef0c-4bd0-9893-c8df06446cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 10))\n",
    "sns.histplot(x=tropes_characters_ethnicity_df['BoxOffice'], color = 'red', ax=axes[0,0], kde=True)\n",
    "axes[0,0].set_title('Box Office Histogram')\n",
    "\n",
    "sns.boxplot(x=tropes_characters_ethnicity_df['BoxOffice'], color = 'red', ax=axes[0,1])\n",
    "axes[0,1].set_title('Box Office Box Plot')\n",
    "\n",
    "sns.histplot(x=tropes_characters_ethnicity_df['ActorHeight'], color = 'lime', ax = axes[1,0], kde = True)\n",
    "axes[1,0].set_title('Actor Height Histogram')\n",
    "\n",
    "sns.boxplot(x=tropes_characters_ethnicity_df['ActorHeight'], color = 'lime', ax = axes[1,1])\n",
    "axes[1,1].set_title('Actor Height Box Plot')\n",
    "\n",
    "sns.histplot(x=tropes_characters_ethnicity_df['ActorAge'], color = 'pink', ax = axes[2,0], kde = True)\n",
    "axes[2,0].set_title('Actor Age Histogram')\n",
    "\n",
    "sns.boxplot(x=tropes_characters_ethnicity_df['ActorAge'], color = 'pink', ax = axes[2,1])\n",
    "axes[2,1].set_title('Actor Age Box Plot')\n",
    "\n",
    "sns.countplot(x='Decade', data=tropes_characters_ethnicity_df, palette='viridis', ax = axes[3,0])\n",
    "axes[3,0].set_title('Number of Movies Released per Decade')\n",
    "axes[3,0].set_xlabel('Decade')\n",
    "axes[3,0].set_ylabel('Number of Movies')\n",
    "\n",
    "sns.boxplot(x=tropes_characters_ethnicity_df['Decade'], palette = 'viridis', ax = axes[3,1])\n",
    "axes[3,1].set_title('Movies per Decade Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e2ef7-f653-44d1-92e3-c2d08a65e94c",
   "metadata": {},
   "source": [
    "> + For BoxOffice, we observe a skewed power law distribution, with a large number of extreme outliers and a large concentration of movies having a low box office number (in terms of millions). <br>\n",
    "> + For ActorHeight, we observe a bimodal distribution that could be explained by the presence of two populations, Female and Male actors. We will plot this distribution in function of gender to correlate with our observation. <br>\n",
    "> + For Actor Age, we observe a normal distribution, with the mean being at around 37 years old. There are though a few outliers in the 70s and 80s. <br>\n",
    "> + We plot the number of movies by decade. We notice a similar distribution to our initial plot of movies per decade, for movies_df. As such, our filter has not biased the decade distribution of our movies. Our boxplot shows the same skewed distribution towards the left, with a outliers in the 1920s to 1940s. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c97b60-4936-4b5a-9199-e3fae0bea809",
   "metadata": {},
   "source": [
    "#### d.ii) Bivariate EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d320f43-07d8-492c-88bd-b88f0e4eebd0",
   "metadata": {},
   "source": [
    "##### Actor Height per Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37476eae-f1ef-47d3-ae7e-dae769ad8c89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "sns.scatterplot(x='ActorName', y='ActorHeight', hue='ActorGender', data=tropes_characters_ethnicity_df, \n",
    "                palette={'M': 'pink', 'F': 'green'}, s=150, ax=axes[0])\n",
    "axes[0].set_xticks([])\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('Height (in meters)')\n",
    "axes[0].set_title('Actor Height Scatter Plot')\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(0, 1))\n",
    "\n",
    "sns.histplot(x=tropes_characters_ethnicity_df['ActorHeight'], color = 'lime', ax = axes[1], \n",
    "             hue=tropes_characters_ethnicity_df['ActorGender'],palette={'M': 'pink', 'F': 'green'}, kde = True)\n",
    "axes[1].set_title('Actor Height Histogram')\n",
    "axes[1].set_xlabel('Actor Heights (in meters)')\n",
    "axes[1].set_ylabel('')\n",
    "axes[1].set_title('Actor Height Histogram')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5281a5e0-5ff5-43aa-9b4c-173555887cc7",
   "metadata": {},
   "source": [
    ">Our earlier hypothesis about ActorHeight distribution being a bimodal distribution sectioned by gender is wrong, as indicated in the histogram on the left. Indeed, the population of female actors is too low to impact the male actor height distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253e80dd-209e-472e-a800-8919a8128210",
   "metadata": {},
   "source": [
    "##### Height by Trope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242806f8-3dff-49b5-b514-1f6655e81139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.barplot(x='Trope', y = 'ActorHeight', data= tropes_characters_ethnicity_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(bottom=1.65, top = 1.9)\n",
    "plt.xlabel('Character Tropes')\n",
    "plt.ylabel('Actor Height (in meters)')\n",
    "plt.title('Average Height per Character Trope')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf390e84-0bfd-48bc-9eda-1f159daafac6",
   "metadata": {},
   "source": [
    "> We plot the average height per character trope. We notice that some tropes have much lower average height. This could be due to some tropes be stereotypically feminine ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a34fd3b-b0ad-44b5-9af7-f61180133687",
   "metadata": {},
   "source": [
    "##### Number of Characters per Trope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6621b1e-a894-47ee-93af-a2bc264d0ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tropes_characters_ethnicity_df['Trope'].hist(bins=72, xrot=90,figsize=(15,6))\n",
    "plt.title('Number of Character per Trope Histogram')\n",
    "plt.xlabel('Trope')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1872e18-8f75-4a24-92ce-19c659fb24cc",
   "metadata": {},
   "source": [
    ">We plot the number of characters by tropes. We notice that some character tropes have very low numbers of characters associated, such as *classy_cat_burglar, klutz*, and, *pupil_turned_to_evil*. <br>\n",
    ">A solution to this issue could be grouping similar character tropes together, for example *klutz* could be associated with *ditz* to constitute the trope *clumsy_person*.\n",
    ">Sadly we do not have access to the FreebaseID Dataset that David Bamman, Brendan O'Connor, and Noah Smith used to create their unique character personas as it is not available anymore. They based themselves on key words from the plot summaries to create character maps and derive the tropes from said maps. <br>\n",
    ">As such, we will opt for a more rudimentary approach by manually grouping similar tropes together. This will be done in function of their definition on [TV Tropes](https://tvtropes.org/), as used by Bamman, O'Connor & Smith and our personal knowledge.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a62f52-3dd7-4f51-a1f1-e90a89d79a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Let us create the archetypes detailed above as 15 different lists\n",
    "skilled_badass = ['master_swordsman', 'warrior_poet', 'cultured_badass', 'fastest_gun_in_the_west', \n",
    "                  'adventurer_archaeologist', 'hitman_with_a_heart']\n",
    "loser = ['doormat', 'coward', 'henpecked_husband', 'dean_bitterman', 'loser_protagonist']\n",
    "laidback_freebird = ['junkie_prophet', 'slacker', 'stoner', 'surfer_dude']\n",
    "jock = ['bully', 'jerk_jock', 'dumb_muscle', 'arrogant_kungfu_guy', 'bruiser_with_a_soft_center']\n",
    "charismatic_charmer = ['loveable_rogue', 'byronic_hero', 'casanova', 'charmer', 'big_man_on_campus', \n",
    "                       'gentleman_thief', 'classy_cat_burglar']\n",
    "respected_leader = ['officer_and_a_gentleman', 'father_to_his_men', 'self_made_man', 'the_chief']\n",
    "crazy_fighter = ['bounty_hunter', 'psycho_for_hire', 'tranquil_fury', 'crazy_survivalist']\n",
    "dumb_and_clumsy = ['brainless_beauty', 'dumb_blonde', 'ditz', 'klutz', 'stupid_crooks']\n",
    "shallow_and_popular = ['final_girl', 'valley_girl', 'prima_donna', 'granola_person', 'chanteuse']\n",
    "old_wise_quirky = ['eccentric_mentor', 'retired_outlaw', 'hardboiled_detective', 'absent_minded_professor']\n",
    "sidekick = ['romantic_runnerup', 'storyteller', 'young_gun', 'bromantic_foil']\n",
    "emotional_damage = ['heartbroken_badass', 'ophelia', 'broken_bird']\n",
    "evil_character = ['revenge', 'evil_prince', 'egomaniac_hunter', 'pupil_turned_to_evil', 'trickster']\n",
    "mean_officer = ['consummate_professional', 'dirty_cop', 'corrupt_corporate_executive', 'the_editor', 'grumpy_old_man', \n",
    "                'drill_sargeant_nasty', 'morally_bankrupt_banker']\n",
    "tech_genius = ['child_prodigy', 'gadgeteer_genius', 'playful_hacker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1868d502-04cd-4cb2-b81f-2ad19f18aba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Replacing the tropes in tropes_character_ethnicity_df by their new grouped archetypes one by one\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=skilled_badass, \n",
    "                                                                                          value='skilled_badass')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=loser, \n",
    "                                                                                          value='loser')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=laidback_freebird, \n",
    "                                                                                          value='laidback_freebird')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=jock, \n",
    "                                                                                          value='jock')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=charismatic_charmer, \n",
    "                                                                                          value='charismatic_charmer')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=respected_leader, \n",
    "                                                                                          value='respected_leader')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=crazy_fighter, \n",
    "                                                                                          value='crazy_fighter')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=dumb_and_clumsy, \n",
    "                                                                                          value='dumb_and_clumsy')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=shallow_and_popular, \n",
    "                                                                                          value='shallow_and_popular')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=old_wise_quirky, \n",
    "                                                                                          value='old_wise_quirky')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=sidekick, \n",
    "                                                                                          value='sidekick')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=emotional_damage, \n",
    "                                                                                          value='emotional_damage')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=evil_character, \n",
    "                                                                                          value='evil_character')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=mean_officer, \n",
    "                                                                                          value='mean_officer')\n",
    "tropes_characters_ethnicity_df['Trope'] = tropes_characters_ethnicity_df['Trope'].replace(to_replace=tech_genius, \n",
    "                                                                                          value='tech_genius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763541a-3b0a-43ff-9373-a5c7fec855b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "trope_plot = sns.histplot(data=tropes_characters_ethnicity_df, x='Trope', bins=16, edgecolor='black', stat='count', \n",
    "             hue='Trope', palette='deep',legend = False, kde=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of Tropes')\n",
    "plt.xlabel('Trope')\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ddf45",
   "metadata": {},
   "source": [
    "##### Exploring the relations between genres and tropes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e064fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duplicates row values for each individual genre found in Genres\n",
    "tropes_genres_exploded=tropes_characters_ethnicity_df.explode('Genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c085090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('In our reduced dataset we count ' + str(tropes_genres_exploded['Genres'].nunique()) + ' unique genres')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14345d73",
   "metadata": {},
   "source": [
    ">Having 182 unique genres, plotting the number of tropes appearances per genre would be a mess. Instead we can plot the number of unique genres each trope appears in. Such a plot would give us an insight wether or not a trope is specific for a certain genre or if tropes in general can be found in multiple genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb035c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots a histogram of the number of genres a given trope is present in\n",
    "genre_count =pd.DataFrame(tropes_genres_exploded.groupby('Trope')['Genres'].nunique())\n",
    "sns.barplot(data=genre_count,x=genre_count.index, y='Genres')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Number of unique genres in which a trope appears ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e38bcd",
   "metadata": {},
   "source": [
    ">From this plot we learn that our trope categories are general enought to cover at least 40 different genres. This will enables us to compare actors characteristics for a given trope accross different genres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09f15e-ba37-4ea3-a298-4a6fdaa41903",
   "metadata": {},
   "source": [
    "### Step 3: Actor Images Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d126e4",
   "metadata": {},
   "source": [
    ">In this part we want to extract actors' facial encodings, in order to use them as features for classification. We are using the *actor_images.csv* file that we've created. It contains actor names, their correspoding pictures stored as a url with it's width and height. The code for that file can be found in the *people_images.ipynb* notebook.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1cffbd-3205-49dd-af74-742d65ab05d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "actor_images = pd.read_csv('data/our_datasets/actor_images.csv')\n",
    "actor_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8315213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding missing values \n",
    "missing = actor_images == '-'\n",
    "missing_images = actor_images[missing.any(axis=1)]\n",
    "print(missing_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d67f6",
   "metadata": {},
   "source": [
    ">Only 0.85% of the data is missing. We will disregard it for now as it is marginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#actor_images without the missing urls\n",
    "actor_cleaned = actor_images[~missing.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f895ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get face encodings using the face_recognition library\n",
    "#this cell runs for ~10 minutes\n",
    "face_encodings = {'Actor': [], 'Encodings': []}\n",
    "\n",
    "for index, row in actor_cleaned.iterrows():\n",
    "    actor_name = row['Actor']\n",
    "    image_url = row['Image URL']\n",
    "\n",
    "    # Remove spaces from actor name\n",
    "    #retrieve image url\n",
    "    img = requests.get(image_url)\n",
    "    image_content = BytesIO(img.content)\n",
    "\n",
    "    #transmfor the image into an array\n",
    "    img = np.asarray(Image.open(image_content))\n",
    "    \n",
    "    #extract facial encodings (coordinates)\n",
    "    face_landmarks_list = face_recognition.face_landmarks(img)\n",
    "\n",
    "    face_encodings['Encodings'].append(face_landmarks_list)\n",
    "    face_encodings['Actor'].append(actor_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532690f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dataframe containing the facial encodings for each actor\n",
    "face_encodings = pd.DataFrame(face_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da810cd",
   "metadata": {},
   "source": [
    ">Having extracted the facial encodings for each actor, we want to retrieve features that we will use for classification. For the sake of comparison between actors, we will use proportions of certain landmarks with respect to two reference measures: one for face width (distance betweem the temples) and one for the face length (distance between the top of the nose bridge and the lowest point of the chin). For exemple, we will not look at the length of a nose, but as its size in proportion to the reference length. <br>\n",
    ">For this milestone, we are only focussing on three features: nose length and width and distance between eyes. More features will be extracted for the final analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd194ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_proportions(row):\n",
    "    try:\n",
    "        landmarks = row['Encodings'][0]  # Extract the dictionary from the list\n",
    "    except (json.JSONDecodeError, IndexError):\n",
    "        # Handle cases where 'Encodings' is not a valid JSON or the list is empty\n",
    "        return pd.Series({'Actor': row['Actor'],'Eye Distance': np.nan, 'Nose Length': np.nan, 'Nose Width': np.nan})\n",
    "\n",
    "    \n",
    "    chin_landmarks = landmarks['chin']\n",
    "    nose_landmarks = landmarks['nose_bridge']\n",
    "    nose_width_landmarks = landmarks['nose_tip']\n",
    "\n",
    "    if not chin_landmarks or not nose_landmarks or not nose_width_landmarks:\n",
    "        # Handle cases where expected landmarks are not available\n",
    "        return pd.Series({'Actor': row['Actor'],'Eye Distance': np.nan,'Nose Length': np.nan, 'Nose Width': np.nan})\n",
    "\n",
    "    x1 = chin_landmarks[0][0]\n",
    "    x2 = chin_landmarks[-1][0]\n",
    "    y1 = nose_landmarks[0][1]\n",
    "    y2 = chin_landmarks[9][1]\n",
    "\n",
    "    x_max = np.abs(x2 - x1)\n",
    "    y_max = np.abs(y2 - y1)\n",
    "\n",
    "    left_eye = landmarks.get('left_eye', [])\n",
    "    right_eye = landmarks.get('right_eye', [])\n",
    "\n",
    "    if not left_eye or not right_eye:\n",
    "        eye_dist = np.nan\n",
    "    else: \n",
    "        x_r = right_eye[0][0]\n",
    "        x_l = left_eye[2][0]\n",
    "        eye_dist = abs(x_r - x_l) / x_max\n",
    "\n",
    "\n",
    "    y_nose1 = nose_landmarks[0][1]\n",
    "    y_nose2 = nose_width_landmarks[-1][1]\n",
    "    x_nose1 = nose_width_landmarks[0][0]\n",
    "    x_nose2 = nose_width_landmarks[-1][0]\n",
    "\n",
    "    nose_length = abs(y_nose2 - y_nose1) / y_max\n",
    "    nose_width = abs(x_nose2 - x_nose1) / x_max\n",
    "\n",
    "    return pd.Series({'Actor': row['Actor'],'Eye Distance': eye_dist, 'Nose Length': nose_length, 'Nose Width': nose_width})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456ef29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply the face_proportions function to all actors \n",
    "facial_proportions = face_encodings.apply(face_proportions, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d18661",
   "metadata": {},
   "source": [
    ">**Features visualisation** Now that we have obtained the features (proportions of different disctinctives facial features, such as nose length, distance between eyes, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = facial_proportions[['Eye Distance', 'Nose Length', 'Nose Width']]\n",
    "\n",
    "# Create the pairplot\n",
    "sns.pairplot(feature_columns, kind='scatter', diag_kind='hist', corner=True)\n",
    "plt.suptitle('Feature visualisation', y=1.02, size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a4b0b",
   "metadata": {},
   "source": [
    "> We observe that the nose length is normally distributed, whereas the eye distance and nose width are skewed to the right and left, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd32671",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = feature_columns.corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', cbar=False, mask=mask)\n",
    "plt.title('Correlation Matrix (Lower Triangular)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ed2be4",
   "metadata": {},
   "source": [
    "The box plots allow us to visualise outliers . Disgarding feature outliers can improve model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4b55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=feature_columns, palette='Set2')\n",
    "plt.title('Box Plots for Facial Proportions')\n",
    "plt.ylabel('Facial Proportions {%}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356f71a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_summaries = pd.DataFrame(facial_proportions.describe())\n",
    "display(column_summaries)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
