{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the appropriate libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn.objects as so\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import ast\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "#image analysis: first install dlib in your ada environment (1: conda activate ada , 2: install dlib)\n",
    "import dlib \n",
    "#face recognition library, first install it in your ada environment (1: conda activate ada, 2: install face_recognition)\n",
    "import face_recognition\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads \"actor_images.csv\" file\n",
    "actor_images = pd.read_csv('data/our_datasets/actor_images.csv')\n",
    "actor_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding missing values \n",
    "missing = actor_images == '-'\n",
    "missing_images = actor_images[missing.any(axis=1)]\n",
    "print(missing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actor_images without the missing urls\n",
    "actor_cleaned = actor_images[~missing.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_encodings = {'Actor': [], 'Landmarks': [], 'Encodings':[]}\n",
    "def landmarks (row):\n",
    "    actor_name = row['Actor']\n",
    "    image_url = row['Image URL']\n",
    "\n",
    "    try:\n",
    "        # Retrieve image URL\n",
    "        img = requests.get(image_url)\n",
    "        image_content = BytesIO(img.content)\n",
    "\n",
    "        # Transform the image into an array\n",
    "        img_array = np.asarray(Image.open(image_content))\n",
    "\n",
    "        # Extract facial encodings (coordinates)\n",
    "        face_landmarks_list = face_recognition.face_landmarks(img_array)\n",
    "        \n",
    "        if face_landmarks_list:\n",
    "            face_encodings_list = face_recognition.face_encodings(img_array)\n",
    "                                                                  \n",
    "        else:\n",
    "            face_encodings_list = np.nan\n",
    "\n",
    "    except Exception as e:\n",
    "        face_landmarks_list = np.nan\n",
    "        face_encodings_list = np.nan\n",
    "        \n",
    "    return pd.Series({'Actor': actor_name, 'Landmarks': face_landmarks_list, 'Encodings':face_encodings_list})\n",
    "    \n",
    "#face_encodings = actor_cleaned.apply(lambda row: landmarks(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_encodings = pd.read_csv(\"encodings2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing encodings is 12.103746%\n"
     ]
    }
   ],
   "source": [
    "face_encodings_cleaned = face_encodings.dropna()\n",
    "missing =(len(face_encodings)-len(face_encodings_cleaned))/len(face_encodings)\n",
    "print('Number of missing encodings is {:%}'.format(missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_proportions(row):\n",
    "\n",
    "    facial_prop = pd.Series({\n",
    "        'Actor': row['Actor'],\n",
    "        'Eye Distance': np.nan,\n",
    "        'Eye Position': np.nan,\n",
    "        'Nose Length': np.nan,\n",
    "        'Nose Width': np.nan,\n",
    "        'Eyebrow Length': np.nan,\n",
    "        'Face Shape': np.nan,\n",
    "        'Cheek Bones': np.nan})\n",
    " \n",
    "    try:\n",
    "        landmarks = row['Encodings'][0] \n",
    "    except (json.JSONDecodeError, IndexError):\n",
    "        # Handle cases where 'Encodings' is not a valid JSON or the list is empty\n",
    "        return facial_prop\n",
    "\n",
    "    chin_landmarks = landmarks['chin']\n",
    "    nose_landmarks = landmarks['nose_bridge']\n",
    "    nose_width_landmarks = landmarks['nose_tip']\n",
    "    left_eyebrow_landmarks = landmarks['left_eyebrow']\n",
    "    right_eyebrow_landmakrs = landmarks['right_eyebrow']\n",
    "    left_eye_landmarks = landmarks['left_eye']\n",
    "    right_eye_landmarks = landmarks['right_eye']\n",
    "    top_lip_landmarks = landmarks['top_lip']\n",
    "\n",
    "    if not chin_landmarks or not nose_landmarks:\n",
    "        return facial_prop\n",
    "\n",
    "    #Get the maximum distance for x and y => we will standardize the distances by dividing them by the max values \n",
    "    x1 = chin_landmarks[0][0]\n",
    "    x2 = chin_landmarks[-1][0]\n",
    "    y1 = nose_landmarks[0][1]\n",
    "    y2 = chin_landmarks[8][1]\n",
    "\n",
    "    x_max = np.abs(x2 - x1)\n",
    "    y_max = np.abs(y2 - y1)\n",
    "\n",
    "    #Get Eye Distance\n",
    "    #Eye Position: distance between the eyes and the edge of the chin (in y distance)\n",
    "    if not left_eye_landmarks or not right_eye_landmarks:\n",
    "        eye_dist = np.nan\n",
    "        eye_position = np.nan\n",
    "    else: \n",
    "        x_r = right_eye_landmarks[0][0]\n",
    "        x_l = left_eye_landmarks[3][0]\n",
    "        eye_dist = abs(x_r - x_l) / x_max\n",
    "\n",
    "        y_r = right_eye_landmarks[0][1]\n",
    "        y_l = left_eye_landmarks[3][1]\n",
    "        chin_r = chin_landmarks[7][1]\n",
    "        chin_l = chin_landmarks[9][1]\n",
    "\n",
    "        eye_position = (abs(y_r - chin_r)/y_max + abs(y_l - chin_l)/y_max)/2\n",
    "\n",
    "\n",
    "    facial_prop['Eye Distance'] = eye_dist\n",
    "    facial_prop['Eye Position'] = eye_position \n",
    "\n",
    "\n",
    "\n",
    "    # Get nose withd and nose length\n",
    "    if not nose_landmarks or not nose_width_landmarks:\n",
    "        nose_length  = np.nan\n",
    "        nose_width  = np.nan\n",
    "    else:\n",
    "        y_nose1 = nose_landmarks[0][1]\n",
    "        y_nose2 = nose_width_landmarks[-1][1]\n",
    "        x_nose1 = nose_width_landmarks[0][0]\n",
    "        x_nose2 = nose_width_landmarks[-1][0]\n",
    "\n",
    "        nose_length = abs(y_nose2 - y_nose1) / y_max\n",
    "        nose_width = abs(x_nose2 - x_nose1) / x_max\n",
    "\n",
    "    facial_prop['Nose Length'] = nose_length\n",
    "    facial_prop['Nose Width'] = nose_width\n",
    "\n",
    "\n",
    "    #Eye brow length: do for both eye brows and take the mean\n",
    "    if not left_eyebrow_landmarks or not right_eyebrow_landmakrs:\n",
    "        eyebrow_length = np.nan\n",
    "    else: \n",
    "        x1_eyebrowl = left_eyebrow_landmarks[0][0]\n",
    "        x2_eyebrowl = left_eyebrow_landmarks[-1][0]\n",
    "        x1_eyebrowr = right_eyebrow_landmakrs[0][0]\n",
    "        x2_eyebrowr = right_eyebrow_landmakrs[-1][0]\n",
    "        eyebrow_length = (abs(x2_eyebrowl - x1_eyebrowl)/x_max + abs(x2_eyebrowr - x1_eyebrowr)/x_max)/2\n",
    "\n",
    "    facial_prop['Eyebrow Length'] = eyebrow_length\n",
    "\n",
    "    #Face shape: for the face shape, we will do face width on face length ratio . if close to 1 the face is square, if close to zero the face is long and narrow and if bigger than 1 the face is short and broad.\n",
    "    face_shape = x_max / y_max\n",
    "    facial_prop['Face Shape'] = face_shape\n",
    "\n",
    "    # Cheek bones: x distance from chin[0] to chin[5]\n",
    "    chin5 = chin_landmarks[5][0]\n",
    "    chin11 = chin_landmarks[11][0]\n",
    "    cheek_bones = (abs(chin5 - x1)/x_max + abs(chin11 - x2)/x_max)/2\n",
    "\n",
    "    facial_prop['Cheek Bones'] = cheek_bones\n",
    "\n",
    "    return facial_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m facial_proportions \u001b[39m=\u001b[39m face_encodings_cleaned\u001b[39m.\u001b[39;49mapply(face_proportions, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/frame.py:9423\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9412\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9414\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9415\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9416\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9421\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9422\u001b[0m )\n\u001b[0;32m-> 9423\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/anaconda3/envs/ada/lib/python3.9/site-packages/pandas/core/apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (json\u001b[39m.\u001b[39mJSONDecodeError, \u001b[39mIndexError\u001b[39;00m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Handle cases where 'Encodings' is not a valid JSON or the list is empty\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m facial_prop\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m chin_landmarks \u001b[39m=\u001b[39m landmarks[\u001b[39m'\u001b[39;49m\u001b[39mchin\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m nose_landmarks \u001b[39m=\u001b[39m landmarks[\u001b[39m'\u001b[39m\u001b[39mnose_bridge\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/izapomykalska/Desktop/ADA/ada-2023-project-adacadabra1000101/facial_recognition.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m nose_width_landmarks \u001b[39m=\u001b[39m landmarks[\u001b[39m'\u001b[39m\u001b[39mnose_tip\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "facial_proportions = face_encodings_cleaned.apply(face_proportions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = facial_proportions.drop('Actor', axis =1)\n",
    "feature_columns = feature_columns.dropna()\n",
    "\n",
    "def reg_coef(x,y,label=None,color=None,**kwargs):\n",
    "    ax = plt.gca()\n",
    "    r,p = pearsonr(x,y)\n",
    "    ax.annotate('r = {:.2f}'.format(r), xy=(0.5,0.5), xycoords='axes fraction', ha='center')\n",
    "    ax.set_axis_off()\n",
    "# Create the pairplot\n",
    "g = sns.PairGrid(feature_columns)\n",
    "g.map_diag(sns.distplot)\n",
    "g.map_lower(sns.regplot)\n",
    "g.map_upper(reg_coef)\n",
    "\n",
    "plt.suptitle('Feature visualisation', y=1.02, size=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a boxplot for each face proportion\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=feature_columns, palette='Set2')\n",
    "plt.title('Box Plots for Facial Proportions')\n",
    "plt.ylabel('Facial Proportions {%}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge tropes_characters_ethnicity_df with facial_proportions\n",
    "\n",
    "facial_proportions= facial_proportions.rename(columns={'Actor': 'ActorName'})\n",
    "tropes = tropes_characters_ethnicity_df[['Trope','ActorName']]\n",
    "tropes_facial_features = tropes.merge(facial_proportions, on=['ActorName'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropes_facial_features_plot = tropes_facial_features.drop('ActorName',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melted = pd.melt(tropes_facial_features_plot, id_vars='Trope', var_name='Feature', value_name='Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(x='Trope', y='Values', hue='Feature', data=df_melted)\n",
    "plt.xlabel('Trope')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Bar Plot for facial features grouped by character tropes')\n",
    "plt.legend(title='Features', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_euclidean = face_encodings_cleaned.drop([face_encodings_cleaned.index[97],face_encodings_cleaned.index[131],face_encodings_cleaned.index[156]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,302):\n",
    "    if len(faces_euclidean['Encodings'].iloc[i]) > 1:\n",
    "        length = len(faces_euclidean['Encodings'].iloc[i])\n",
    "        print('Row number {} has {} encoding vectors'.format(i,length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(encoding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_euclidean['Dist'] = faces_euclidean['Encodings'].apply(euclidean_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_euclidean.reset_index(drop=True, inplace=True)\n",
    "faces_euclidean['ActorID'] = faces_euclidean.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_attributes = tropes_characters_ethnicity_df[['Trope','ActorName','ActorGender','ActorHeight','ActorDOB']]\n",
    "faces_euclidean_trope = actor_attributes.merge(faces_euclidean, on=['ActorName'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_euclidean_trope.to_csv('actor_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_values = faces_euclidean['Dist'].values\n",
    "\n",
    "# Convert the list of lists to a NumPy array\n",
    "matrix_array = np.array([x for x in matrix_values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
