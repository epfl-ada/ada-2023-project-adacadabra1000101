{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from collections import Counter\n",
    "import re\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import json\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "#image analysis: first install dlib in your ada environment (1: conda activate ada , 2: install dlib)\n",
    "import dlib \n",
    "#face recognition library, first install it in your ada environment (1: conda activate ada, 2: install face_recognition)\n",
    "import face_recognition\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_images = pd.read_csv('data/our_datasets/actor_images.csv')\n",
    "actor_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = actor_images == '-'\n",
    "missing_images = actor_images[missing.any(axis=1)]\n",
    "print(missing_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_cleaned = actor_images[~missing.any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_encodings = {'Actor': [], 'Encodings': []}\n",
    "\n",
    "for index, row in actor_cleaned.iterrows():\n",
    "    actor_name = row['Actor']\n",
    "    image_url = row['Image URL']\n",
    "\n",
    "    # Remove spaces from actor name\n",
    "\n",
    "    img = requests.get(image_url)\n",
    "    image_content = BytesIO(img.content)\n",
    "    img = np.asarray(Image.open(image_content))\n",
    "    face_landmarks_list = face_recognition.face_landmarks(img)\n",
    "    face_encodings['Encodings'].append(face_landmarks_list)\n",
    "    face_encodings['Actor'].append(actor_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
